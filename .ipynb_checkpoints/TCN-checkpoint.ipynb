{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95f52d1-0c3a-46a7-a1ff-74447944577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75206e63-af08-4534-bba5-ef4e3d46524a",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "1. Data Preparation:\n",
    "   - Load and preprocess data.\n",
    "   - Create lagged features for power consumption and align them with the forecasted temperature data for the next 24 hours.\n",
    "   - Split data into train, validation, and test sets\n",
    "2. Model Definition:\n",
    "   - Use the TCN architecture, which employs causal convolutions to ensure predictions only depend on past data.\n",
    "3. Training:\n",
    "   - Define a loss function and optimizer.\n",
    "   - Train the model using the training set, and monitor validation loss to prevent overfitting.\n",
    "8. Evaluation:\n",
    "   - Predict the next 24 hours on the test set.\n",
    "   - Compare TCN predictions with SARIMA using evaluation metrics like RMSE, MAE, and MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a051b1-0016-40df-bac4-baba30d0acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Set print options to suppress scientific notation and show 3 decimal places\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "# Suppress all warnings globally\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effd6b01-1bb2-4f0e-a781-27b54c9fbd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(current_directory, 'data_augmented/X_small.csv')\n",
    "X_small = pd.read_csv(file_path, index_col = 0)\n",
    "\n",
    "file_path = os.path.join(current_directory, 'data_augmented/timestamps.csv')\n",
    "timestamps = pd.read_csv(file_path, index_col = 0)\n",
    "\n",
    "file_path = os.path.join(current_directory, 'data_augmented/temperature.csv')\n",
    "temperature = pd.read_csv(file_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b53eaf3-4a8c-4f36-a5bd-a9e7acd129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_small "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ce7fab-05b7-42dc-bf75-2438885468e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = timestamps\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.asfreq('H')  # 'H' for hourly frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1050efe1-ccaa-46fc-8935-3b29d7920e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tcn_features(df, target_col, window_length=168, forecast_horizon=24):\n",
    "    \"\"\"\n",
    "    Prepares the feature and target tensors for TCN.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with historical data.\n",
    "        power_col (str): Column name for power consumption.\n",
    "        temp_col (str): Column name for temperature.\n",
    "        window_length (int): Length of the temporal window (168 for 7 days).\n",
    "        forecast_horizon (int): Forecast horizon (24 for next 24 hours).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Feature tensor of shape (num_samples, window_length, num_features).\n",
    "        np.ndarray: Target tensor of shape (num_samples, forecast_horizon).\n",
    "        pd.DatetimeIndex: Timestamps corresponding to each sample.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Prepare features and targets\n",
    "    X, y = [], []\n",
    "    timestamps = []\n",
    "\n",
    "    for i in range(len(df) - window_length - forecast_horizon + 1):\n",
    "        # Extract historic features\n",
    "        features = df.iloc[i:i + window_length].values  # (window_length, num_features)\n",
    "        X.append(features)\n",
    "\n",
    "        # Extract target (next 24 hours of power consumption)\n",
    "        y.append(df.iloc[i + window_length:i + window_length + forecast_horizon][target_col].values)\n",
    "\n",
    "        # Timestamps for the target period\n",
    "        timestamps.append(df.index[i + window_length])\n",
    "\n",
    "    return np.array(X), np.array(y), pd.DatetimeIndex(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656ae011-c167-44ac-a758-fba31f04ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tcn_features_with_forecast(df, target_col, exog_cols, window_length=168, forecast_horizon=24):\n",
    "    \"\"\"\n",
    "    Prepares the feature and target tensors for TCN with integrated forecasted features,\n",
    "    filling missing values instead of dropping them.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with historical data.\n",
    "        target_col (str): Column name for power consumption (target variable).\n",
    "        exog_cols (list): List of column names for weather variables.\n",
    "        window_length (int): Length of the historical temporal window (e.g., 168 for 7 days).\n",
    "        forecast_horizon (int): Forecast horizon (e.g., 24 for next 24 hours).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Feature tensor of shape (num_samples, window_length, num_features).\n",
    "        np.ndarray: Target tensor of shape (num_samples, forecast_horizon).\n",
    "        pd.DatetimeIndex: Timestamps corresponding to each sample.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add forecasted weather features\n",
    "    for col in exog_cols:\n",
    "        for h in range(1, forecast_horizon + 1):\n",
    "            df[f'{col}_forecast_{h}h'] = df[col].shift(-h)\n",
    "\n",
    "    # Fill missing values (forward fill and backward fill as fallback)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Prepare features and targets\n",
    "    X, y = [], []\n",
    "    timestamps = []\n",
    "\n",
    "    for i in range(len(df) - window_length - forecast_horizon + 1):\n",
    "        # Extract historical and forecasted features\n",
    "        features = df.iloc[i:i + window_length].values  # (window_length, num_features)\n",
    "        X.append(features)\n",
    "\n",
    "        # Extract target (next 24 hours of power consumption)\n",
    "        y.append(df.iloc[i + window_length:i + window_length + forecast_horizon][target_col].values)\n",
    "\n",
    "        # Timestamps for the target period\n",
    "        timestamps.append(df.index[i + window_length])\n",
    "\n",
    "    return np.array(X), np.array(y), pd.DatetimeIndex(timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf2bbbc-a9b0-4461-915a-db60e8335e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>ghi</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_spring</th>\n",
       "      <th>is_summer</th>\n",
       "      <th>is_autumn</th>\n",
       "      <th>is_winter</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_daylight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-13 10:00:00+00:00</th>\n",
       "      <td>0.21837</td>\n",
       "      <td>2.31866</td>\n",
       "      <td>0.44842</td>\n",
       "      <td>-0.83739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 11:00:00+00:00</th>\n",
       "      <td>-0.11143</td>\n",
       "      <td>2.09107</td>\n",
       "      <td>0.56725</td>\n",
       "      <td>-0.36810</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 12:00:00+00:00</th>\n",
       "      <td>-0.16639</td>\n",
       "      <td>1.98543</td>\n",
       "      <td>0.69246</td>\n",
       "      <td>0.11499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 13:00:00+00:00</th>\n",
       "      <td>-0.03585</td>\n",
       "      <td>1.27027</td>\n",
       "      <td>0.76656</td>\n",
       "      <td>0.01837</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 14:00:00+00:00</th>\n",
       "      <td>0.30769</td>\n",
       "      <td>1.71318</td>\n",
       "      <td>0.79978</td>\n",
       "      <td>-0.17487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 01:00:00+00:00</th>\n",
       "      <td>-1.06418</td>\n",
       "      <td>-0.65983</td>\n",
       "      <td>-0.05753</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 02:00:00+00:00</th>\n",
       "      <td>-1.05848</td>\n",
       "      <td>-0.65983</td>\n",
       "      <td>-0.09075</td>\n",
       "      <td>-0.21628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 03:00:00+00:00</th>\n",
       "      <td>-1.02523</td>\n",
       "      <td>-0.65983</td>\n",
       "      <td>-0.07669</td>\n",
       "      <td>-0.25768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 04:00:00+00:00</th>\n",
       "      <td>-0.76414</td>\n",
       "      <td>-0.49193</td>\n",
       "      <td>0.05363</td>\n",
       "      <td>-0.54754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 05:00:00+00:00</th>\n",
       "      <td>-0.29126</td>\n",
       "      <td>-0.13911</td>\n",
       "      <td>0.32960</td>\n",
       "      <td>-1.11344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           power_consumption      ghi     temp     wind  \\\n",
       "timestamp                                                                 \n",
       "2022-04-13 10:00:00+00:00            0.21837  2.31866  0.44842 -0.83739   \n",
       "2022-04-13 11:00:00+00:00           -0.11143  2.09107  0.56725 -0.36810   \n",
       "2022-04-13 12:00:00+00:00           -0.16639  1.98543  0.69246  0.11499   \n",
       "2022-04-13 13:00:00+00:00           -0.03585  1.27027  0.76656  0.01837   \n",
       "2022-04-13 14:00:00+00:00            0.30769  1.71318  0.79978 -0.17487   \n",
       "...                                      ...      ...      ...      ...   \n",
       "2024-06-17 01:00:00+00:00           -1.06418 -0.65983 -0.05753 -0.23008   \n",
       "2024-06-17 02:00:00+00:00           -1.05848 -0.65983 -0.09075 -0.21628   \n",
       "2024-06-17 03:00:00+00:00           -1.02523 -0.65983 -0.07669 -0.25768   \n",
       "2024-06-17 04:00:00+00:00           -0.76414 -0.49193  0.05363 -0.54754   \n",
       "2024-06-17 05:00:00+00:00           -0.29126 -0.13911  0.32960 -1.11344   \n",
       "\n",
       "                           is_weekend  is_spring  is_summer  is_autumn  \\\n",
       "timestamp                                                                \n",
       "2022-04-13 10:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 11:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 12:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 13:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 14:00:00+00:00           0          1          0          0   \n",
       "...                               ...        ...        ...        ...   \n",
       "2024-06-17 01:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 02:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 03:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 04:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 05:00:00+00:00           0          0          1          0   \n",
       "\n",
       "                           is_winter  is_holiday  is_daylight  \n",
       "timestamp                                                      \n",
       "2022-04-13 10:00:00+00:00          0           0            1  \n",
       "2022-04-13 11:00:00+00:00          0           0            1  \n",
       "2022-04-13 12:00:00+00:00          0           0            1  \n",
       "2022-04-13 13:00:00+00:00          0           0            1  \n",
       "2022-04-13 14:00:00+00:00          0           0            1  \n",
       "...                              ...         ...          ...  \n",
       "2024-06-17 01:00:00+00:00          0           0            0  \n",
       "2024-06-17 02:00:00+00:00          0           0            0  \n",
       "2024-06-17 03:00:00+00:00          0           0            0  \n",
       "2024-06-17 04:00:00+00:00          0           0            0  \n",
       "2024-06-17 05:00:00+00:00          0           0            0  \n",
       "\n",
       "[19100 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3500408-0f82-486d-bb7f-d4f485127d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"power_consumption\"\n",
    "exog_cols = ['temp'] # [col for col in df.columns if col not in target_col]\n",
    "window_length = 168  # 7 days\n",
    "forecast_horizon = 24  # Next 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "422d91c6-d5b6-4064-9240-35938bb0bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train-Test Split\n",
    "train_size = int(len(df) * 0.8)  # Determine initial train size based on 80%\n",
    "initial_test_start = train_size  \n",
    "\n",
    "while df.index[initial_test_start].hour != 11: # Adjust test start to align with the next occurrence of 11 AM\n",
    "    initial_test_start += 1\n",
    "\n",
    "final_test_end = len(df) - 1\n",
    "while df.index[final_test_end].hour != 10: # Adjust test end to align with the last 10 AM in the dataset\n",
    "    final_test_end -= 1\n",
    "\n",
    "train = df.iloc[:initial_test_start]\n",
    "test = df.iloc[initial_test_start:final_test_end+1]  # Include the last index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b159b4e0-c6f8-4697-97df-90164ee6f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_forecasted_data = 1\n",
    "\n",
    "if include_forecasted_data:\n",
    "    X, y, timestamps = prepare_tcn_features_with_forecast(df, target_col, exog_cols, window_length, forecast_horizon)\n",
    "    X_train, y_train, timestamps_train = prepare_tcn_features_with_forecast(train, target_col, exog_cols, window_length, forecast_horizon)\n",
    "    X_test, y_test, timestamps_test = prepare_tcn_features_with_forecast(test, target_col, exog_cols, window_length, forecast_horizon)\n",
    "else:\n",
    "    X, y, timestamps = prepare_tcn_features(df, target_col, window_length, forecast_horizon)\n",
    "    X_train, y_train, timestamps_train = prepare_tcn_features(train, target_col, window_length, forecast_horizon)\n",
    "    X_test, y_test, timestamps_test = prepare_tcn_features(test, target_col, window_length, forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc46254f-d61a-4e9c-8d69-5441fd01f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size=3, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Temporal Convolutional Network for Power Consumption Forecasting.\n",
    "\n",
    "        Parameters:\n",
    "            input_size (int): Number of input features.\n",
    "            output_size (int): Number of output features (forecast horizon).\n",
    "            num_channels (list): Number of channels in each TCN layer.\n",
    "            kernel_size (int): Size of the convolution kernel.\n",
    "            dropout (float): Dropout rate.\n",
    "        \"\"\"\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(num_channels)):\n",
    "            in_channels = input_size if i == 0 else num_channels[i - 1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=(kernel_size - 1)),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the TCN.\n",
    "\n",
    "        Input:\n",
    "            x: Shape (batch_size, seq_length, input_size).\n",
    "        Output:\n",
    "            y: Shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, input_size, seq_length)\n",
    "        x = self.network(x)\n",
    "        x = x[:, :, -1]  # Take the last time step\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f6dd64d-14a8-432f-a444-0b6c4a25d36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use the MPS device for Apple Silicon\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA if available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Default to CPU if no GPU backend is available\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138358bd-8764-44da-87cc-e09417e455bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6088\n",
      "Epoch 2, Loss: 0.4297\n",
      "Epoch 3, Loss: 0.3759\n",
      "Epoch 4, Loss: 0.3517\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the TCN model\n",
    "input_size = X.shape[2]  # Number of features per time step\n",
    "output_size = y.shape[1]  # Forecast horizon (24 hours)\n",
    "hidden_channels = [64, 128, 64]  # Number of channels in hidden layers\n",
    "\n",
    "model = TemporalConvNet(input_size, output_size, hidden_channels, kernel_size=3, dropout=0.2).to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_X)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        end_time = time.time()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}, Time: {end_time-start_time:.2f} seconds\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(test_predictions, y_test_tensor.to(device)).item()\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f338a-b9b9-43c6-bdb1-19747746e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_np = test_predictions.cpu().detach().numpy()  # (num_test_samples, forecast_horizon)\n",
    "\n",
    "num_samples, forecast_horizon = test_predictions_np.shape  \n",
    "\n",
    "aligned_matrix = np.full((num_samples, num_samples+forecast_horizon-1), np.nan)\n",
    "for i in range(num_samples):  \n",
    "    aligned_matrix[i, i:i + forecast_horizon] = test_predictions_np[i] \n",
    "\n",
    "column_names = [timestamps_test[0] + pd.Timedelta(hours=i) for i in np.arange(0,num_samples+forecast_horizon)]\n",
    "aligned_df = pd.DataFrame(aligned_matrix, columns=column_names)\n",
    "aligned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8f980-2a6b-4c80-a5ea-bffbba452d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_ahead_forecast(y_pred, y_true, prediction_timestamps, forecast_horizon=24):\n",
    "    \"\"\"\n",
    "    Generate direct day-ahead forecasts without rolling mean.\n",
    "    Predicts at time k the next k+24 hours and aligns predictions with test timestamps.\n",
    "    \"\"\"\n",
    "    predictions = []  # Store predictions for each 24-hour window\n",
    "    actuals = []\n",
    "\n",
    "    # Loop through the test set in steps of 24 (non-overlapping)\n",
    "    for i in range(0, len(y_pred), forecast_horizon):\n",
    "        \n",
    "        predictions.append(y_pred[i])\n",
    "        actuals.append(y_true[i])\n",
    "\n",
    "    \n",
    "    # Convert predictions and timestamps to a Pandas Series\n",
    "    predictions_series = pd.Series(\n",
    "        np.concatenate(predictions),  # Flatten the list of forecasts\n",
    "        index=prediction_timestamps  # Align with timestamps\n",
    "    )\n",
    "    \n",
    "    # Convert predictions and timestamps to a Pandas Series\n",
    "    actuals_series = pd.Series(\n",
    "        np.concatenate(actuals),  # Flatten the list of forecasts\n",
    "        index=prediction_timestamps  # Align with timestamps\n",
    "    )\n",
    "    return predictions_series, actuals_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29b846-c097-45b4-8655-057a115cc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(pred, act, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(test.index[:len(pred)], act, label=\"Actual\")\n",
    "    plt.plot(test.index[:len(pred)], pred, label=\"Predicted\", linestyle=\"--\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Power Consumption\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b8e2a-8f30-4737-a022-d6909fd183ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_timestamps = [timestamps_test[0] + pd.Timedelta(hours=i) for i in np.arange(1,num_samples+forecast_horizon)]\n",
    "y_pred = test_predictions_np\n",
    "y_true = np.array(y_test)\n",
    "predictions, actuals = day_ahead_forecast(y_pred, y_true, prediction_timestamps, 24)\n",
    "plot_results(predictions, actuals, \"Day-Ahead Power Consumption Forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7d524-6a2a-4a4b-8b4d-9ace41137d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_by_month(pred, act, title):\n",
    "\n",
    "    pred.index = pd.to_datetime(pred.index)\n",
    "    act.index = pd.to_datetime(act.index)\n",
    "\n",
    "    # Group data by month\n",
    "    months = pred.index.month.unique()\n",
    "    num_months = len(months)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=num_months, ncols=1, figsize=(50, 4 * num_months), sharex=False)\n",
    "    if num_months == 1:  # If there's only one month, axes is not a list\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, month in zip(axes, months):\n",
    "        # Filter data for the current month\n",
    "        pred_month = pred[pred.index.month == month]\n",
    "        act_month = act[act.index.month == month]\n",
    "        \n",
    "        # Plot the data\n",
    "        ax.plot(act_month.index, act_month, label=\"Actual\")\n",
    "        ax.plot(pred_month.index, pred_month, label=\"Predicted\", linestyle=\"--\")\n",
    "        \n",
    "        # Customize the subplot\n",
    "        ax.set_title(f\"Month: {month}\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(\"Power Consumption\")\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "    # Add overall title and layout adjustment\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959ccaf-8c72-49de-ab1c-35ed4752192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_by_month(predictions, actuals, \"Day-Ahead Power Consumption Forecast, per month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b05b2d-37ee-44b1-8d01-2478c3a81315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# RMSE\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "# MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) # * 100\n",
    "\n",
    "# ME\n",
    "from sklearn.metrics import max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1d5d5-f57e-42e5-9a65-2d106cb4f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['TCN prediction at 10 am', 'TCN predictions at all time steps']\n",
    "error_dict = {'model': models,\n",
    "              'RMSE': np.zeros(len(models)),\n",
    "              'MAE': np.zeros(len(models)),\n",
    "              'ME': np.zeros(len(models)),\n",
    "              'MAPE': np.zeros(len(models))\n",
    "    }\n",
    "errors = pd.DataFrame(error_dict).set_index(\"model\")\n",
    "errors = pd.DataFrame(error_dict).set_index(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9a8ba-9fe3-4d50-8ab7-dca060de6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.loc[models[0], 'RMSE'] = root_mean_squared_error(actuals, predictions)\n",
    "errors.loc[models[0], 'MAE'] = mean_absolute_error(actuals, predictions)\n",
    "errors.loc[models[0], 'ME'] = max_error(actuals, predictions)\n",
    "errors.loc[models[0], 'MAPE'] = mean_absolute_percentage_error(actuals, predictions)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36703efc-da90-4a2c-b780-894a9584b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.loc[models[1], 'RMSE'] = root_mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
    "errors.loc[models[1], 'MAE'] = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "errors.loc[models[1], 'ME'] = max_error(y_true.flatten(), y_pred.flatten())\n",
    "errors.loc[models[1], 'MAPE'] = mean_absolute_percentage_error(y_true.flatten(), y_pred.flatten())\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab566d2-4266-48fc-8a31-c42941bfc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors / np.max(errors, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0043e5-26e9-46a9-b7f7-dd85ab721d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734599e-0ba5-4f48-b3e4-8234f33a961f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63238bc1-0370-4549-8fef-f8c121cb24f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

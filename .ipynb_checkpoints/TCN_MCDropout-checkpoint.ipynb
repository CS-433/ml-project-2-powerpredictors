{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95f52d1-0c3a-46a7-a1ff-74447944577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75206e63-af08-4534-bba5-ef4e3d46524a",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "1. Data Preparation:\n",
    "   - Load and preprocess data.\n",
    "   - Create lagged features for power consumption and align them with the forecasted temperature data for the next 24 hours.\n",
    "   - Split data into train, validation, and test sets\n",
    "2. Model Definition:\n",
    "   - Use the TCN architecture, which employs causal convolutions to ensure predictions only depend on past data.\n",
    "3. Training:\n",
    "   - Define a loss function and optimizer.\n",
    "   - Train the model using the training set, and monitor validation loss to prevent overfitting.\n",
    "8. Evaluation:\n",
    "   - Predict the next 24 hours on the test set.\n",
    "   - Compare TCN predictions with SARIMA using evaluation metrics like RMSE, MAE, and MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a051b1-0016-40df-bac4-baba30d0acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Set print options to suppress scientific notation and show 3 decimal places\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "# Suppress all warnings globally\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effd6b01-1bb2-4f0e-a781-27b54c9fbd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(current_directory, 'data_augmented/X_small.csv')\n",
    "X_small = pd.read_csv(file_path, index_col = 0)\n",
    "\n",
    "file_path = os.path.join(current_directory, 'data_augmented/timestamps.csv')\n",
    "timestamps = pd.read_csv(file_path, index_col = 0)\n",
    "\n",
    "file_path = os.path.join(current_directory, 'data_augmented/temperature.csv')\n",
    "temperature = pd.read_csv(file_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b53eaf3-4a8c-4f36-a5bd-a9e7acd129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_small "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ce7fab-05b7-42dc-bf75-2438885468e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = timestamps\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.asfreq('H')  # 'H' for hourly frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1050efe1-ccaa-46fc-8935-3b29d7920e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tcn_features(df, target_col, window_length=168, forecast_horizon=24):\n",
    "    \"\"\"\n",
    "    Prepares the feature and target tensors for TCN.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with historical data.\n",
    "        power_col (str): Column name for power consumption.\n",
    "        temp_col (str): Column name for temperature.\n",
    "        window_length (int): Length of the temporal window (168 for 7 days).\n",
    "        forecast_horizon (int): Forecast horizon (24 for next 24 hours).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Feature tensor of shape (num_samples, window_length, num_features).\n",
    "        np.ndarray: Target tensor of shape (num_samples, forecast_horizon).\n",
    "        pd.DatetimeIndex: Timestamps corresponding to each sample.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Prepare features and targets\n",
    "    X, y = [], []\n",
    "    timestamps = []\n",
    "\n",
    "    for i in range(len(df) - window_length - forecast_horizon + 1):\n",
    "        # Extract historic features\n",
    "        features = df.iloc[i:i + window_length].values  # (window_length, num_features)\n",
    "        X.append(features)\n",
    "\n",
    "        # Extract target (next 24 hours of power consumption)\n",
    "        y.append(df.iloc[i + window_length:i + window_length + forecast_horizon][target_col].values)\n",
    "\n",
    "        # Timestamps for the target period\n",
    "        timestamps.append(df.index[i + window_length])\n",
    "\n",
    "    return np.array(X), np.array(y), pd.DatetimeIndex(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf2bbbc-a9b0-4461-915a-db60e8335e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>ghi</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_spring</th>\n",
       "      <th>is_summer</th>\n",
       "      <th>is_autumn</th>\n",
       "      <th>is_winter</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_daylight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-13 10:00:00+00:00</th>\n",
       "      <td>0.21837</td>\n",
       "      <td>2.31866</td>\n",
       "      <td>0.44842</td>\n",
       "      <td>-0.83739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 11:00:00+00:00</th>\n",
       "      <td>-0.11143</td>\n",
       "      <td>2.09107</td>\n",
       "      <td>0.56725</td>\n",
       "      <td>-0.36810</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 12:00:00+00:00</th>\n",
       "      <td>-0.16639</td>\n",
       "      <td>1.98543</td>\n",
       "      <td>0.69246</td>\n",
       "      <td>0.11499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 13:00:00+00:00</th>\n",
       "      <td>-0.03585</td>\n",
       "      <td>1.27027</td>\n",
       "      <td>0.76656</td>\n",
       "      <td>0.01837</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-13 14:00:00+00:00</th>\n",
       "      <td>0.30769</td>\n",
       "      <td>1.71318</td>\n",
       "      <td>0.79978</td>\n",
       "      <td>-0.17487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 01:00:00+00:00</th>\n",
       "      <td>-1.06418</td>\n",
       "      <td>-0.65983</td>\n",
       "      <td>-0.05753</td>\n",
       "      <td>-0.23008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 02:00:00+00:00</th>\n",
       "      <td>-1.05848</td>\n",
       "      <td>-0.65983</td>\n",
       "      <td>-0.09075</td>\n",
       "      <td>-0.21628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 03:00:00+00:00</th>\n",
       "      <td>-1.02523</td>\n",
       "      <td>-0.65983</td>\n",
       "      <td>-0.07669</td>\n",
       "      <td>-0.25768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 04:00:00+00:00</th>\n",
       "      <td>-0.76414</td>\n",
       "      <td>-0.49193</td>\n",
       "      <td>0.05363</td>\n",
       "      <td>-0.54754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-17 05:00:00+00:00</th>\n",
       "      <td>-0.29126</td>\n",
       "      <td>-0.13911</td>\n",
       "      <td>0.32960</td>\n",
       "      <td>-1.11344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           power_consumption      ghi     temp     wind  \\\n",
       "timestamp                                                                 \n",
       "2022-04-13 10:00:00+00:00            0.21837  2.31866  0.44842 -0.83739   \n",
       "2022-04-13 11:00:00+00:00           -0.11143  2.09107  0.56725 -0.36810   \n",
       "2022-04-13 12:00:00+00:00           -0.16639  1.98543  0.69246  0.11499   \n",
       "2022-04-13 13:00:00+00:00           -0.03585  1.27027  0.76656  0.01837   \n",
       "2022-04-13 14:00:00+00:00            0.30769  1.71318  0.79978 -0.17487   \n",
       "...                                      ...      ...      ...      ...   \n",
       "2024-06-17 01:00:00+00:00           -1.06418 -0.65983 -0.05753 -0.23008   \n",
       "2024-06-17 02:00:00+00:00           -1.05848 -0.65983 -0.09075 -0.21628   \n",
       "2024-06-17 03:00:00+00:00           -1.02523 -0.65983 -0.07669 -0.25768   \n",
       "2024-06-17 04:00:00+00:00           -0.76414 -0.49193  0.05363 -0.54754   \n",
       "2024-06-17 05:00:00+00:00           -0.29126 -0.13911  0.32960 -1.11344   \n",
       "\n",
       "                           is_weekend  is_spring  is_summer  is_autumn  \\\n",
       "timestamp                                                                \n",
       "2022-04-13 10:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 11:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 12:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 13:00:00+00:00           0          1          0          0   \n",
       "2022-04-13 14:00:00+00:00           0          1          0          0   \n",
       "...                               ...        ...        ...        ...   \n",
       "2024-06-17 01:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 02:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 03:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 04:00:00+00:00           0          0          1          0   \n",
       "2024-06-17 05:00:00+00:00           0          0          1          0   \n",
       "\n",
       "                           is_winter  is_holiday  is_daylight  \n",
       "timestamp                                                      \n",
       "2022-04-13 10:00:00+00:00          0           0            1  \n",
       "2022-04-13 11:00:00+00:00          0           0            1  \n",
       "2022-04-13 12:00:00+00:00          0           0            1  \n",
       "2022-04-13 13:00:00+00:00          0           0            1  \n",
       "2022-04-13 14:00:00+00:00          0           0            1  \n",
       "...                              ...         ...          ...  \n",
       "2024-06-17 01:00:00+00:00          0           0            0  \n",
       "2024-06-17 02:00:00+00:00          0           0            0  \n",
       "2024-06-17 03:00:00+00:00          0           0            0  \n",
       "2024-06-17 04:00:00+00:00          0           0            0  \n",
       "2024-06-17 05:00:00+00:00          0           0            0  \n",
       "\n",
       "[19100 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3500408-0f82-486d-bb7f-d4f485127d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"power_consumption\"\n",
    "window_length = 168  # 7 days\n",
    "forecast_horizon = 24  # Next 24 hours\n",
    "\n",
    "# Reduce the feature space dimension\n",
    "# df = df[['power_consumption', 'temp']]\n",
    "\n",
    "# Add forecasted temperature data\n",
    "# df['temp_forecast'] = temperature[window_length : len(df) + window_length]['temperature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422d91c6-d5b6-4064-9240-35938bb0bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train-Test Split\n",
    "train_size = int(len(df) * 0.8)  # Determine initial train size based on 80%\n",
    "initial_test_start = train_size  \n",
    "\n",
    "while df.index[initial_test_start].hour != 11: # Adjust test start to align with the next occurrence of 11 AM\n",
    "    initial_test_start += 1\n",
    "\n",
    "final_test_end = len(df) - 1\n",
    "while df.index[final_test_end].hour != 10: # Adjust test end to align with the last 10 AM in the dataset\n",
    "    final_test_end -= 1\n",
    "\n",
    "train = df.iloc[:initial_test_start]\n",
    "test = df.iloc[initial_test_start:final_test_end+1]  # Include the last index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa4393b-7fe5-4a33-9ce1-496edec0f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, timestamps = prepare_tcn_features(df, target_col, window_length, forecast_horizon)\n",
    "X_train, y_train, timestamps_train = prepare_tcn_features(train, target_col, window_length, forecast_horizon)\n",
    "X_test, y_test, timestamps_test = prepare_tcn_features(test, target_col, window_length, forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc46254f-d61a-4e9c-8d69-5441fd01f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size=3, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Temporal Convolutional Network for Power Consumption Forecasting.\n",
    "\n",
    "        Parameters:\n",
    "            input_size (int): Number of input features.\n",
    "            output_size (int): Number of output features (forecast horizon).\n",
    "            num_channels (list): Number of channels in each TCN layer.\n",
    "            kernel_size (int): Size of the convolution kernel.\n",
    "            dropout (float): Dropout rate.\n",
    "        \"\"\"\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(num_channels)):\n",
    "            in_channels = input_size if i == 0 else num_channels[i - 1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=(kernel_size - 1)),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)  # Dropout layer\n",
    "            ]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the TCN.\n",
    "\n",
    "        Input:\n",
    "            x: Shape (batch_size, seq_length, input_size).\n",
    "        Output:\n",
    "            y: Shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, input_size, seq_length)\n",
    "        x = self.network(x)\n",
    "        x = x[:, :, -1]  # Take the last time step\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def enable_mc_dropout(self):\n",
    "        \"\"\"Enable MC Dropout by setting all dropout layers to train mode.\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Dropout):\n",
    "                module.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b0fa75-5219-46f6-a072-703b630dbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_predictions(model, X, num_samples=100):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo Dropout predictions.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): TCN model with MC Dropout enabled.\n",
    "        X (torch.Tensor): Input tensor of shape (batch_size, seq_length, num_features).\n",
    "        num_samples (int): Number of MC samples.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Mean predictions.\n",
    "        torch.Tensor: Prediction standard deviations (uncertainty).\n",
    "    \"\"\"\n",
    "    model.enable_mc_dropout()  # Enable dropout during testing\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        with torch.no_grad():\n",
    "            predictions.append(model(X))  # Append prediction for each MC sample\n",
    "\n",
    "    predictions = torch.stack(predictions)  # Shape: (num_samples, batch_size, output_size)\n",
    "    mean_prediction = predictions.mean(dim=0)  # Mean over MC samples\n",
    "    uncertainty = predictions.std(dim=0)  # Std dev over MC samples\n",
    "\n",
    "    return mean_prediction, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f6dd64d-14a8-432f-a444-0b6c4a25d36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use the MPS device for Apple Silicon\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA if available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Default to CPU if no GPU backend is available\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138358bd-8764-44da-87cc-e09417e455bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6301\n",
      "Epoch 2, Loss: 0.4389\n",
      "Epoch 3, Loss: 0.4142\n",
      "Epoch 4, Loss: 0.4046\n",
      "Epoch 5, Loss: 0.3985\n",
      "Epoch 6, Loss: 0.3930\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the TCN model\n",
    "input_size = X.shape[2]  # Number of features per time step\n",
    "output_size = y.shape[1]  # Forecast horizon (24 hours)\n",
    "hidden_channels = [64, 128, 64]  # Number of channels in hidden layers\n",
    "\n",
    "model = TemporalConvNet(input_size, output_size, hidden_channels, kernel_size=3, dropout=0.2).to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# === Training Loop ===\n",
    "num_epochs = 10\n",
    "model.train()  # Enable training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_X)  # Forward pass\n",
    "        loss = criterion(predictions, batch_y)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# === Evaluation with MC Dropout ===\n",
    "model.eval()  # Enable evaluation mode\n",
    "\n",
    "# Use MC Dropout for predictions\n",
    "num_samples = 100  # Number of Monte Carlo samples\n",
    "mean_predictions, uncertainties = monte_carlo_predictions(model, X_test_tensor.to(device), num_samples)\n",
    "\n",
    "# Compute test loss using the mean prediction\n",
    "test_loss = criterion(mean_predictions, y_test_tensor.to(device)).item()\n",
    "print(f\"Test Loss (MC Dropout): {test_loss:.4f}\")\n",
    "\n",
    "# Convert results to numpy arrays for further analysis\n",
    "mean_predictions_np = mean_predictions.cpu().numpy()  # Mean predictions\n",
    "uncertainties_np = uncertainties.cpu().numpy()  # Prediction uncertainties\n",
    "\n",
    "# Example: Print predictions and uncertainties for the first test sample\n",
    "print(\"Mean Predictions (First Test Sample):\", mean_predictions_np[0])\n",
    "print(\"Uncertainties (First Test Sample):\", uncertainties_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002520c-9cc9-4583-bb85-1df8d9e4fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = np.arange(mean_predictions_np.shape[1])\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, mean_predictions_np[0], label=\"Mean Prediction\", color=\"blue\")\n",
    "plt.fill_between(\n",
    "    time_steps,\n",
    "    mean_predictions_np[0] - 1.96 * uncertainties_np[0],\n",
    "    mean_predictions_np[0] + 1.96 * uncertainties_np[0],\n",
    "    color=\"blue\",\n",
    "    alpha=0.3,\n",
    "    label=\"95% Confidence Interval\"\n",
    ")\n",
    "plt.title(\"Predictions with Uncertainty\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Power Consumption\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c66473-c83d-4e6d-98bc-552168e39280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82115b19-0d3b-47dc-90f4-b31020894a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e63e39-9c57-4269-8b0c-2dff07621c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_picp_pinaw(y_true, y_lower, y_upper):\n",
    "    \"\"\"\n",
    "    Computes PICP (Prediction Interval Coverage Probability) and \n",
    "    PINAW (Prediction Interval Normalized Average Width).\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): True values of the target variable.\n",
    "        y_lower (array-like): Lower bounds of the prediction intervals.\n",
    "        y_upper (array-like): Upper bounds of the prediction intervals.\n",
    "    \n",
    "    Returns:\n",
    "        picp (float): Prediction Interval Coverage Probability.\n",
    "        pinaw (float): Prediction Interval Normalized Average Width.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays for easier manipulation\n",
    "    y_true = np.array(y_true)\n",
    "    y_lower = np.array(y_lower)\n",
    "    y_upper = np.array(y_upper)\n",
    "    \n",
    "    # PICP: Proportion of true values within the bounds\n",
    "    coverage = (y_true >= y_lower) & (y_true <= y_upper)  # Boolean array\n",
    "    picp = np.mean(coverage)  # Average of the boolean array\n",
    "    \n",
    "    # PINAW: Average width of intervals, normalized by the range of y_true\n",
    "    interval_widths = y_upper - y_lower\n",
    "    pinaw = np.mean(interval_widths) / (np.max(y_true) - np.min(y_true))\n",
    "    \n",
    "    return picp, pinaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383ea7a-8f59-48a3-9507-cb2fdbfbe245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picp, pinaw = compute_picp_pinaw(y_true, y_lower, y_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734599e-0ba5-4f48-b3e4-8234f33a961f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63238bc1-0370-4549-8fef-f8c121cb24f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

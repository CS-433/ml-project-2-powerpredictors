{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add your system path here\n",
    "sys_path = r'C:\\Users\\Max Tost\\Desktop\\Notebooks\\PowerPrediction\\ml-project-2-powerpredictors'\n",
    "sys.path.append(sys_path)\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x = sys_path + r'\\data\\X.csv'\n",
    "x = pd.read_csv(path_x)\n",
    "x = x.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "path_y = sys_path + r'\\data\\Y.csv'\n",
    "y = pd.read_csv(path_y)\n",
    "y = y.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ghi</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_monday</th>\n",
       "      <th>is_tuesday</th>\n",
       "      <th>is_wednesday</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_lag_23</th>\n",
       "      <th>wind_lag_24</th>\n",
       "      <th>wind_diff</th>\n",
       "      <th>ghi_x_temp</th>\n",
       "      <th>ghi_x_wind</th>\n",
       "      <th>temp_x_wind</th>\n",
       "      <th>Temperature_Index</th>\n",
       "      <th>CDD</th>\n",
       "      <th>HDD</th>\n",
       "      <th>wind_power_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>733.01</td>\n",
       "      <td>15.20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11141.7520</td>\n",
       "      <td>557.0876</td>\n",
       "      <td>11.5520</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.268873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>677.00</td>\n",
       "      <td>16.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>10920.0100</td>\n",
       "      <td>744.7000</td>\n",
       "      <td>17.7430</td>\n",
       "      <td>5.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>651.00</td>\n",
       "      <td>17.11</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11138.6100</td>\n",
       "      <td>943.9500</td>\n",
       "      <td>24.8095</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.56</td>\n",
       "      <td>1.867283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>475.00</td>\n",
       "      <td>17.69</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>8402.7500</td>\n",
       "      <td>655.5000</td>\n",
       "      <td>24.4122</td>\n",
       "      <td>4.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.87</td>\n",
       "      <td>1.609694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>584.00</td>\n",
       "      <td>17.95</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>10482.8000</td>\n",
       "      <td>724.1600</td>\n",
       "      <td>22.2580</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.167807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>0.00</td>\n",
       "      <td>11.24</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.4880</td>\n",
       "      <td>10.76</td>\n",
       "      <td>5737.47</td>\n",
       "      <td>202614.07</td>\n",
       "      <td>1.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>0.00</td>\n",
       "      <td>10.98</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.2858</td>\n",
       "      <td>11.02</td>\n",
       "      <td>5737.47</td>\n",
       "      <td>202625.09</td>\n",
       "      <td>1.085081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>0.00</td>\n",
       "      <td>11.09</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.0862</td>\n",
       "      <td>10.91</td>\n",
       "      <td>5737.47</td>\n",
       "      <td>202636.00</td>\n",
       "      <td>1.006357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>41.32</td>\n",
       "      <td>12.11</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>500.3852</td>\n",
       "      <td>40.0804</td>\n",
       "      <td>11.7467</td>\n",
       "      <td>9.89</td>\n",
       "      <td>5737.47</td>\n",
       "      <td>202645.89</td>\n",
       "      <td>0.559012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>128.15</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.17</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1828.7005</td>\n",
       "      <td>71.7640</td>\n",
       "      <td>7.9912</td>\n",
       "      <td>7.73</td>\n",
       "      <td>5737.47</td>\n",
       "      <td>202653.62</td>\n",
       "      <td>0.107565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ghi   temp  wind  year  month  day  hour  is_monday  is_tuesday  \\\n",
       "0      733.01  15.20  0.76  2022      4   13    10          0           0   \n",
       "1      677.00  16.13  1.10  2022      4   13    11          0           0   \n",
       "2      651.00  17.11  1.45  2022      4   13    12          0           0   \n",
       "3      475.00  17.69  1.38  2022      4   13    13          0           0   \n",
       "4      584.00  17.95  1.24  2022      4   13    14          0           0   \n",
       "...       ...    ...   ...   ...    ...  ...   ...        ...         ...   \n",
       "19095    0.00  11.24  1.20  2024      6   17     1          1           0   \n",
       "19096    0.00  10.98  1.21  2024      6   17     2          1           0   \n",
       "19097    0.00  11.09  1.18  2024      6   17     3          1           0   \n",
       "19098   41.32  12.11  0.97  2024      6   17     4          1           0   \n",
       "19099  128.15  14.27  0.56  2024      6   17     5          1           0   \n",
       "\n",
       "       is_wednesday  ...  wind_lag_23  wind_lag_24  wind_diff  ghi_x_temp  \\\n",
       "0                 1  ...         0.00         0.00       0.00  11141.7520   \n",
       "1                 1  ...         0.00         0.00       0.34  10920.0100   \n",
       "2                 1  ...         0.00         0.00       0.35  11138.6100   \n",
       "3                 1  ...         0.00         0.00      -0.07   8402.7500   \n",
       "4                 1  ...         0.00         0.00      -0.14  10482.8000   \n",
       "...             ...  ...          ...          ...        ...         ...   \n",
       "19095             0  ...         1.08         0.88      -0.02      0.0000   \n",
       "19096             0  ...         1.02         1.08       0.01      0.0000   \n",
       "19097             0  ...         0.88         1.02      -0.03      0.0000   \n",
       "19098             0  ...         1.17         0.88      -0.21    500.3852   \n",
       "19099             0  ...         1.35         1.17      -0.41   1828.7005   \n",
       "\n",
       "       ghi_x_wind  temp_x_wind  Temperature_Index      CDD        HDD  \\\n",
       "0        557.0876      11.5520               6.80     0.00       6.80   \n",
       "1        744.7000      17.7430               5.87     0.00      12.67   \n",
       "2        943.9500      24.8095               4.89     0.00      17.56   \n",
       "3        655.5000      24.4122               4.31     0.00      21.87   \n",
       "4        724.1600      22.2580               4.05     0.00      25.92   \n",
       "...           ...          ...                ...      ...        ...   \n",
       "19095      0.0000      13.4880              10.76  5737.47  202614.07   \n",
       "19096      0.0000      13.2858              11.02  5737.47  202625.09   \n",
       "19097      0.0000      13.0862              10.91  5737.47  202636.00   \n",
       "19098     40.0804      11.7467               9.89  5737.47  202645.89   \n",
       "19099     71.7640       7.9912               7.73  5737.47  202653.62   \n",
       "\n",
       "       wind_power_density  \n",
       "0                0.268873  \n",
       "1                0.815238  \n",
       "2                1.867283  \n",
       "3                1.609694  \n",
       "4                1.167807  \n",
       "...                   ...  \n",
       "19095            1.058400  \n",
       "19096            1.085081  \n",
       "19097            1.006357  \n",
       "19098            0.559012  \n",
       "19099            0.107565  \n",
       "\n",
       "[19100 rows x 115 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26906370656370654"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = sys_path + r'\\data\\dataset_v2.csv'\n",
    "data = LoadData(path)\n",
    "\n",
    "# Showing the relative amount of data that are Nan in a column\n",
    "relnan(data, 'total_p_demand [kW]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "to_normalise = ['total_p_demand [kW]', 'ghi', 'temp', 'wind']\n",
    "for norm in to_normalise:\n",
    "    data[norm] = (data[norm]-data[norm].mean())/data[norm].std() # Improvised normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>total_p_demand [kW]</th>\n",
       "      <th>ghi</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.205988</td>\n",
       "      <td>2.312083</td>\n",
       "      <td>0.458395</td>\n",
       "      <td>-0.834773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.116385</td>\n",
       "      <td>2.085088</td>\n",
       "      <td>0.576724</td>\n",
       "      <td>-0.364855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.170113</td>\n",
       "      <td>1.979716</td>\n",
       "      <td>0.701415</td>\n",
       "      <td>0.118884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.042508</td>\n",
       "      <td>1.266432</td>\n",
       "      <td>0.775211</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0.293297</td>\n",
       "      <td>1.708182</td>\n",
       "      <td>0.808293</td>\n",
       "      <td>-0.171359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21553</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.048182</td>\n",
       "      <td>-0.658625</td>\n",
       "      <td>-0.045457</td>\n",
       "      <td>-0.226644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21554</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.042130</td>\n",
       "      <td>-0.658625</td>\n",
       "      <td>-0.078538</td>\n",
       "      <td>-0.212823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21555</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.011250</td>\n",
       "      <td>-0.658625</td>\n",
       "      <td>-0.064542</td>\n",
       "      <td>-0.254286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21556</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.755178</td>\n",
       "      <td>-0.491166</td>\n",
       "      <td>0.065238</td>\n",
       "      <td>-0.544530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21557</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.294912</td>\n",
       "      <td>-0.139265</td>\n",
       "      <td>0.340066</td>\n",
       "      <td>-1.111196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18174 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month  day  hour  total_p_demand [kW]       ghi      temp  \\\n",
       "2458   2022      4   13    10             0.205988  2.312083  0.458395   \n",
       "2459   2022      4   13    11            -0.116385  2.085088  0.576724   \n",
       "2460   2022      4   13    12            -0.170113  1.979716  0.701415   \n",
       "2461   2022      4   13    13            -0.042508  1.266432  0.775211   \n",
       "2462   2022      4   13    14             0.293297  1.708182  0.808293   \n",
       "...     ...    ...  ...   ...                  ...       ...       ...   \n",
       "21553  2024      6   17     1            -1.048182 -0.658625 -0.045457   \n",
       "21554  2024      6   17     2            -1.042130 -0.658625 -0.078538   \n",
       "21555  2024      6   17     3            -1.011250 -0.658625 -0.064542   \n",
       "21556  2024      6   17     4            -0.755178 -0.491166  0.065238   \n",
       "21557  2024      6   17     5            -0.294912 -0.139265  0.340066   \n",
       "\n",
       "           wind  \n",
       "2458  -0.834773  \n",
       "2459  -0.364855  \n",
       "2460   0.118884  \n",
       "2461   0.022136  \n",
       "2462  -0.171359  \n",
       "...         ...  \n",
       "21553 -0.226644  \n",
       "21554 -0.212823  \n",
       "21555 -0.254286  \n",
       "21556 -0.544530  \n",
       "21557 -1.111196  \n",
       "\n",
       "[18174 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking which sections are Nans to cut them later - At the moment not used because of improvised normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nan_sections = return_nan_sections(data, 'ghi') # Returns array with the first and last index of the data frame where the values are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nan_sections = return_nan_sections(data, 'total_p_demand [kW]') # Returns array with the first and last index of the data frame where the values are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inspecting the outcome\n",
    "# nan_n = 0\n",
    "# data[data.keys()][nan_sections[nan_n][0]-20:nan_sections[nan_n][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0220e+03,  4.0000e+00,  1.3000e+01,  ...,  2.3121e+00,\n",
       "          4.5840e-01, -8.3477e-01],\n",
       "        [ 2.0220e+03,  4.0000e+00,  1.3000e+01,  ...,  2.0851e+00,\n",
       "          5.7672e-01, -3.6486e-01],\n",
       "        [ 2.0220e+03,  4.0000e+00,  1.3000e+01,  ...,  1.9797e+00,\n",
       "          7.0141e-01,  1.1888e-01],\n",
       "        ...,\n",
       "        [ 2.0240e+03,  6.0000e+00,  1.7000e+01,  ..., -6.5863e-01,\n",
       "         -6.4542e-02, -2.5429e-01],\n",
       "        [ 2.0240e+03,  6.0000e+00,  1.7000e+01,  ..., -4.9117e-01,\n",
       "          6.5238e-02, -5.4453e-01],\n",
       "        [ 2.0240e+03,  6.0000e+00,  1.7000e+01,  ..., -1.3927e-01,\n",
       "          3.4007e-01, -1.1112e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.from_numpy(data.to_numpy()) # Convert to torch tensor\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features and targets to train the network\n",
    "Here we will cut the whole data in slices of 7 days, which will be the features. \\\n",
    "The value of the power for the first hour of the 8th day should be the target. \\\n",
    "Then we will save them as features and targets to use them with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MultiTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataset, seq_len=168): # 168 = 7*24 = hours in a week\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            datasets (list of numpy.ndarray): List of time series datasets, \n",
    "                each of shape (n_hours, n_features).\n",
    "            seq_len (int): Length of the input sequence.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        assert dataset.shape[0] > seq_len\n",
    "        for i in range(dataset.shape[0] - seq_len):\n",
    "            # Create input-output pairs for each dataset\n",
    "            x = dataset[i:i + seq_len]\n",
    "            y = dataset[i + seq_len]\n",
    "            self.data.append((x, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming datasets is a list of numpy arrays\n",
    "multi_dataset = MultiTimeSeriesDataset(data)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(multi_dataset))\n",
    "val_size = len(multi_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(multi_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max Tost\\AppData\\Local\\Temp\\ipykernel_840\\2191952570.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Checking shape of train_loader\n",
    "x = np.array([x for x, y in train_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14404, 1, 168, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM-based regression model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features (e.g., temperature, GHI, etc.).\n",
    "            hidden_size (int): Number of units in each LSTM layer.\n",
    "            num_layers (int): Number of stacked LSTM layers.\n",
    "            output_size (int): Number of output features (e.g., predicted demand, 1 for regression).\n",
    "            dropout_prob (float): Dropout probability to apply between LSTM layers and before the fully connected layer.\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # LSTM Layer\n",
    "        # - Processes sequential data and learns temporal dependencies.\n",
    "        # - Supports multiple layers (num_layers) and applies dropout between layers.\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,  # Input/output shape: (batch_size, seq_length, input_size)\n",
    "            dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully Connected (Linear) Layer\n",
    "        # - Maps the LSTM's hidden state output to the desired output size.\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Dropout Layer\n",
    "        # - Reduces overfitting by randomly zeroing some activations during training.\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the LSTM model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, seq_length, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        # LSTM Layer\n",
    "        # - Returns the full sequence of hidden states and the final hidden/cell state tuple.\n",
    "        # - We ignore the hidden/cell state tuple here (h_n, c_n).\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # Dropout Layer\n",
    "        # - Only uses the hidden state from the last time step for prediction.\n",
    "        # - Applies dropout to prevent overfitting.\n",
    "        out = self.dropout(out[:, -1, :])  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        # - Maps the LSTM's output to the desired output size (e.g., single regression output).\n",
    "        out = self.fc(out)  # Shape: (batch_size, output_size)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max Tost\\AppData\\Local\\Temp\\ipykernel_3308\\2191952570.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Validation (optional)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5 min per epoch here on this cpu, validation loss afer 1 epoch: 154743.1982 (Whatever that means)\n",
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMModel(input_size=8, hidden_size=64, num_layers=2, output_size=8, dropout_prob=0.2)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Reset hidden state between sequences\n",
    "        output, hidden = model.lstm(x)\n",
    "        output = model.fc(output[:, -1, :])  # Take last output for regression\n",
    "        #assert output.shape == y.shape\n",
    "        # Compute loss\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation (optional)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            output, _ = model.lstm(x_val)  # Reset hidden state for validation\n",
    "            val_output = model.fc(output[:, -1, :])\n",
    "            val_loss += criterion(val_output, y_val).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction - TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max Tost\\AppData\\Local\\Temp\\ipykernel_5640\\4141761729.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  last_week_data = torch.tensor(data[-168:], dtype=torch.float32)  # Last 7 days of data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "LSTM: Expected input to be 2D or 3D, got 4D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     38\u001b[0m last_week_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m168\u001b[39m:], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Last 7 days of data\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m evaluate_model(model, last_week_data)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "Cell \u001b[1;32mIn[144], line 28\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, initial_data, num_predictions)\u001b[0m\n\u001b[0;32m     26\u001b[0m last_input \u001b[38;5;241m=\u001b[39m initial_data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Shape: [1, 1, num_features]\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_predictions):\n\u001b[1;32m---> 28\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlstm(last_input, hidden)  \u001b[38;5;66;03m# Predict next hour\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc(output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Map hidden state to output\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1074\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m-> 1074\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1075\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1076\u001b[0m         )\n\u001b[0;32m   1077\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m   1078\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: LSTM: Expected input to be 2D or 3D, got 4D instead"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, initial_data, num_predictions=24):\n",
    "    \"\"\"\n",
    "    Evaluate the LSTM to predict the next 24 hours recursively.\n",
    "\n",
    "    Args:\n",
    "        model (LSTMModel): Trained LSTM model.\n",
    "        initial_data (torch.Tensor): Data from the last 7 days (shape: [168, num_features]).\n",
    "        num_predictions (int): Number of hours to predict (default: 24).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Predicted values for the next 24 hours (shape: [24, num_features]).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    # Initialize hidden state with the last 7 days\n",
    "    with torch.no_grad():\n",
    "        input_seq = initial_data.unsqueeze(0)  # Shape: [1, seq_len=168, num_features]\n",
    "        hidden = None  # Let the LSTM initialize hidden state\n",
    "\n",
    "        # Process the last 7 days to initialize hidden state\n",
    "        for t in range(initial_data.size(0)):\n",
    "            _, hidden = model.lstm(input_seq[:, t:t+1, :], hidden)\n",
    "\n",
    "        # Recursive prediction for the next 24 hours\n",
    "        last_input = initial_data[-1, :].unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, num_features]\n",
    "        for _ in range(num_predictions):\n",
    "            output, hidden = model.lstm(last_input, hidden)  # Predict next hour\n",
    "            prediction = model.fc(output[:, -1, :])  # Map hidden state to output\n",
    "            predictions.append(prediction.squeeze(0))\n",
    "\n",
    "            # Use the predicted value as the next input\n",
    "            last_input = prediction.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    return torch.stack(predictions)  # Shape: [24, num_features]\n",
    "\n",
    "# Example usage\n",
    "last_week_data = torch.tensor(data[-168:], dtype=torch.float32)  # Last 7 days of data\n",
    "predictions = evaluate_model(model, last_week_data)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty - TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_predictions(model, x, n_simulations):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo Dropout predictions to estimate both \n",
    "    the mean prediction and uncertainty.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained PyTorch model with dropout layers.\n",
    "        x (torch.Tensor): Input tensor of shape (batch_size, seq_length, input_features).\n",
    "        n_simulations (int): Number of stochastic forward passes to perform.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - mean_pred (torch.Tensor): The mean prediction across all simulations.\n",
    "              Shape: (batch_size, output_features).\n",
    "            - uncertainty (torch.Tensor): The standard deviation of predictions \n",
    "              (representing uncertainty) across simulations.\n",
    "              Shape: (batch_size, output_features).\n",
    "    \"\"\"\n",
    "    # Set the model to train mode to enable dropout during inference\n",
    "    # Dropout layers behave stochastically in train mode, which is necessary for Monte Carlo sampling\n",
    "    model.train()\n",
    "\n",
    "    # Perform n_simulations stochastic forward passes\n",
    "    # Each simulation generates slightly different predictions due to dropout\n",
    "    preds = torch.stack([model(x) for _ in range(n_simulations)])  # Shape: (n_simulations, batch_size, output_features)\n",
    "\n",
    "    # Compute the mean prediction across all simulations\n",
    "    mean_pred = preds.mean(dim=0)  # Shape: (batch_size, output_features)\n",
    "\n",
    "    # Compute the standard deviation across simulations to estimate uncertainty\n",
    "    uncertainty = preds.std(dim=0)  # Shape: (batch_size, output_features)\n",
    "\n",
    "    return mean_pred, uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [x for x, y in val_loader] # Extracting x and y from validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncert = monte_carlo_predictions(model, test_x[0], 100) #finding uncertainty with one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m uncert \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_t \u001b[38;5;129;01min\u001b[39;00m test_x:\n\u001b[1;32m----> 3\u001b[0m     uncert\u001b[38;5;241m.\u001b[39mappend(monte_carlo_predictions(model, x_t, \u001b[38;5;241m100\u001b[39m))\n",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m, in \u001b[0;36mmonte_carlo_predictions\u001b[1;34m(model, x, n_simulations)\u001b[0m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Perform n_simulations stochastic forward passes\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Each simulation generates slightly different predictions due to dropout\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([model(x) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_simulations)])  \u001b[38;5;66;03m# Shape: (n_simulations, batch_size, output_features)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Compute the mean prediction across all simulations\u001b[39;00m\n\u001b[0;32m     28\u001b[0m mean_pred \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size, output_features)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Perform n_simulations stochastic forward passes\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Each simulation generates slightly different predictions due to dropout\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([model(x) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_simulations)])  \u001b[38;5;66;03m# Shape: (n_simulations, batch_size, output_features)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Compute the mean prediction across all simulations\u001b[39;00m\n\u001b[0;32m     28\u001b[0m mean_pred \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size, output_features)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Dropout Layer\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# - Only uses the hidden state from the last time step for prediction.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# - Applies dropout to prevent overfitting.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Shape: (batch_size, hidden_size)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Fully Connected Layer\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# - Maps the LSTM's output to the desired output size (e.g., single regression output).\u001b[39;00m\n\u001b[0;32m     61\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)  \u001b[38;5;66;03m# Shape: (batch_size, output_size)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, p, training)\n\u001b[0;32m   1426\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "uncert = []\n",
    "for x_t in test_x:\n",
    "    uncert.append(monte_carlo_predictions(model, x_t, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 168, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.8918e+02,  6.4641e+00,  1.5547e+01,  1.0813e+01, -6.0888e-01,\n",
       "          2.5608e-01,  2.8174e-01, -4.7669e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
